# Yelp-Data-Analysis

The Yelp Data Analysis project was developed using Databricks and Apache Spark, two popular tools for big data processing and analysis.

The project involved creating a standard cluster and leveraging 32 CPUs to perform parallel computation and analysis on a Yelp dataset that was approximately 11 GB in size. This allowed for efficient and effective processing of the large dataset.

The project also focused on six essential components of distributed systems, including scalability, openness, fault tolerance, clustering, confidentiality, and parallelism. By incorporating these components, the project was able to ensure that the analysis was accurate and reliable, even with such a large and complex dataset.

In order to present the results of the data analysis in a user-friendly way, the project made use of PowerBI for data visualization. This allowed for easy interpretation of the results and helped to identify trends and patterns within the data.

Finally, the project was hosted on the Azure cloud service, making it easily accessible to anyone with an internet connection. This ensured that the insights gained from the data analysis could be shared and utilized by others in the industry.
